{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trunkooze/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load data\n",
    "clean_folder = \"clean\"\n",
    "books_df = pd.read_csv(os.path.join(clean_folder, \"books.csv\"))\n",
    "book_tags_df = pd.read_csv(os.path.join(clean_folder, \"book_tags.csv\"))\n",
    "tags_df = pd.read_csv(os.path.join(clean_folder, \"tags.csv\"))\n",
    "\n",
    "# Standardize column name for merging\n",
    "book_tags_df.rename(columns={'book_id': 'goodreads_book_id'}, inplace=True)\n",
    "\n",
    "# Rename 'book_id' in books_df to 'goodreads_book_id' for merging\n",
    "books_df.rename(columns={'book_id': 'goodreads_book_id'}, inplace=True)\n",
    "\n",
    "# Merge book_tags with tag names\n",
    "book_tags_merged = pd.merge(book_tags_df, tags_df, on='tag_id', how='inner')\n",
    "\n",
    "# Merge with books\n",
    "books_with_tags = pd.merge(\n",
    "    books_df[['goodreads_book_id', 'title', 'authors', 'average_rating',\n",
    "              'ratings_count', 'original_publication_year', 'language_code']],\n",
    "    book_tags_merged,\n",
    "    on='goodreads_book_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Group by book and concatenate tag names into a single string\n",
    "books_tagged = books_with_tags.groupby('goodreads_book_id').agg({\n",
    "    'title': 'first',\n",
    "    'authors': 'first',\n",
    "    'average_rating': 'first',\n",
    "    'ratings_count': 'first',\n",
    "    'original_publication_year': 'first',\n",
    "    'language_code': 'first',\n",
    "    'tag_name': lambda x: ' '.join(set(x))  # deduplicated tag list\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = SentenceTransformer('BAAI/bge-m3')\n",
    "\n",
    "# Encode tag text for each book\n",
    "books_tagged['tag_text'] = books_tagged['tag_name']\n",
    "book_tag_embeddings0 = model.encode(books_tagged['tag_text'].tolist(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_by_multiple_genres(user_genres, top_n=10):\n",
    "    \"\"\"\n",
    "    user_genres: str — comma-separated genres, e.g., \"Fantasy, Mystery, Romance\"\n",
    "    top_n: int — number of results to return\n",
    "    \"\"\"\n",
    "    # Parse and clean genres\n",
    "    genre_list = [g.strip() for g in user_genres.split(',') if g.strip()]\n",
    "    \n",
    "    if not genre_list:\n",
    "        raise ValueError(\"Please input at least one genre!\")\n",
    "\n",
    "    # Embed each genre separately\n",
    "    genre_embeddings = model.encode(genre_list, convert_to_tensor=True)\n",
    "\n",
    "    # Compute average embedding (user profile)\n",
    "    user_embedding = genre_embeddings.mean(dim=0)\n",
    "\n",
    "    # Compute cosine similarity with all books\n",
    "    scores = util.pytorch_cos_sim(user_embedding, book_tag_embeddings0)[0]\n",
    "    top_results = scores.topk(top_n)\n",
    "\n",
    "    # Extract matching rows\n",
    "    results = books_tagged.iloc[top_results[1].cpu().numpy()].copy()\n",
    "    results['similarity'] = top_results[0].cpu().numpy()\n",
    "    return results[[\n",
    "        'goodreads_book_id', 'title', 'authors', 'average_rating',\n",
    "        'ratings_count', 'original_publication_year',\n",
    "        'language_code', 'similarity'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      goodreads_book_id                                              title  \\\n",
      "8910               8911                The Blood Mirror (Lightbringer, #4)   \n",
      "2055               2056                     New Spring (Wheel of Time, #0)   \n",
      "6677               6678  The Wheel of Time: Boxed Set #1 (Wheel of Time...   \n",
      "8550               8551            The Queen's Poisoner (Kingfountain, #1)   \n",
      "5959               5960            Dragon Haven (Rain Wild Chronicles, #2)   \n",
      "8633               8634                                     حوجن [Ḥawjan]   \n",
      "8184               8185     Morgawr (The Voyage of the Jerle Shannara, #3)   \n",
      "6637               6638                   Cross My Heart (Alex Cross, #21)   \n",
      "5066               5067       The Dragon Keeper (Rain Wild Chronicles, #1)   \n",
      "388                 389                    The Final Empire (Mistborn, #1)   \n",
      "\n",
      "                                           authors  average_rating  \\\n",
      "8910                                   Brent Weeks            4.29   \n",
      "2055                                 Robert Jordan            4.01   \n",
      "6677                                 Robert Jordan            4.43   \n",
      "8550                                  Jeff Wheeler            4.07   \n",
      "5959                                    Robin Hobb            4.06   \n",
      "8633  Ibraheem Abbas, إبراهيم عباس, Yasser Bahjatt            3.75   \n",
      "8184                                  Terry Brooks            3.96   \n",
      "6637                               James Patterson            4.03   \n",
      "5066                                    Robin Hobb            3.93   \n",
      "388                              Brandon Sanderson            4.43   \n",
      "\n",
      "      ratings_count  original_publication_year language_code  similarity  \n",
      "8910           4528                     2016.0           eng    0.565139  \n",
      "2055          52823                     2004.0           eng    0.562262  \n",
      "6677          13049                     1990.0          None    0.561967  \n",
      "8550          14126                     2016.0         en-GB    0.559647  \n",
      "5959          15807                     2010.0         en-US    0.554887  \n",
      "8633          10203                     2013.0           ara    0.550009  \n",
      "8184          12797                     2002.0           eng    0.547510  \n",
      "6637          10946                     2013.0           eng    0.546000  \n",
      "5066          19620                     2009.0           eng    0.544394  \n",
      "388          208944                     2006.0           eng    0.540821  \n"
     ]
    }
   ],
   "source": [
    "user_input = \"Fantasy, Science Fiction\"\n",
    "recommendations = recommend_by_multiple_genres(user_input, top_n=10)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(os.path.join(clean_folder, \"ratings_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible users: 30776\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------\n",
    "# 4. Filter Users + Sample\n",
    "# ------------------------------------\n",
    "#   We'll keep only users who rated >60 and <160 books,\n",
    "#   then randomly sample 20% of those rating rows.\n",
    "\n",
    "# Count how many ratings each user did\n",
    "user_counts = ratings_df.groupby('user_id')['book_id'].count().reset_index()\n",
    "user_counts.rename(columns={'book_id': 'count_ratings'}, inplace=True)\n",
    "\n",
    "# Keep those who rated between 60 and 160\n",
    "eligible_users = user_counts[\n",
    "    (user_counts['count_ratings'] > 20) &\n",
    "    (user_counts['count_ratings'] < 30)\n",
    "]\n",
    "print(f\"Eligible users: {len(eligible_users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to keep only those users' ratings\n",
    "filtered_ratings = pd.merge(\n",
    "    ratings_df,\n",
    "    eligible_users[['user_id']],\n",
    "    on='user_id',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered user count: 30776\n",
      "Filtered ratings shape: (745239, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Filtered user count: {len(eligible_users)}\")\n",
    "print(f\"Filtered ratings shape: {filtered_ratings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG: 100%|██████████| 3996/3996 [03:25<00:00, 19.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Average NDCG@10 = 0.4389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "def compute_ndcg_at_k(ground_truth_ids, recommended_ids, user_data, k=10):\n",
    "    \"\"\"\n",
    "    Compute NDCG for a single user at cutoff k, manually.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    ground_truth_ids : set\n",
    "        Set of book_ids the user rated >= 5 (i.e. 'relevant').\n",
    "    recommended_ids : list\n",
    "        List of recommended book_ids in the final top-k (rank order).\n",
    "    user_data : pd.DataFrame\n",
    "        The subset of the ratings DataFrame for this user alone\n",
    "        (so we can look up the actual rating for each book).\n",
    "    k : int\n",
    "        The number of items to consider (already ensured recommended_ids has up to k items).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndcg_val : float\n",
    "        The NDCG for this user at k.\n",
    "    df_debug : pd.DataFrame\n",
    "        A table showing rank, book_id, actual rating, item-level DCG\n",
    "        (so we can see how DCG is accumulated).\n",
    "    \"\"\"\n",
    "    recommended_top_k = recommended_ids[:k]\n",
    "    \n",
    "    # 1) Build a binary relevance list: 1 if rating >=5, else 0\n",
    "    relevance = [1 if b in ground_truth_ids else 0 for b in recommended_top_k]\n",
    "    \n",
    "    # 2) Compute DCG for each rank i in [0..k-1], storing item-level contributions\n",
    "    dcg_values = []\n",
    "    for i, rel in enumerate(relevance):\n",
    "        rank = i + 1  # rank is 1-based\n",
    "        dcg_i = (2 ** rel - 1) / math.log2(rank + 1)\n",
    "        dcg_values.append(dcg_i)\n",
    "    \n",
    "    dcg = sum(dcg_values)\n",
    "    \n",
    "    # 3) Compute IDCG by sorting relevance in descending order\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    idcg_values = []\n",
    "    for i, rel in enumerate(ideal_relevance):\n",
    "        rank = i + 1\n",
    "        idcg_i = (2 ** rel - 1) / math.log2(rank + 1)\n",
    "        idcg_values.append(idcg_i)\n",
    "    \n",
    "    idcg = sum(idcg_values)\n",
    "    ndcg_val = dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    # Build a debug DataFrame\n",
    "    debug_rows = []\n",
    "    for i, book_id in enumerate(recommended_top_k):\n",
    "        rank = i + 1\n",
    "        # Actual rating from user_data\n",
    "        row = user_data[user_data['book_id'] == book_id]\n",
    "        rating = row['rating'].values[0] if not row.empty else 0\n",
    "        \n",
    "        debug_rows.append({\n",
    "            'Rank': rank,\n",
    "            'book_id': book_id,\n",
    "            'User Rating': rating,\n",
    "            'DCG Contribution': dcg_values[i]\n",
    "        })\n",
    "        \n",
    "    df_debug = pd.DataFrame(debug_rows)\n",
    "    \n",
    "    return ndcg_val, df_debug\n",
    "\n",
    "def evaluate_ndcg(ratings_subset, top_n=10):\n",
    "    \"\"\"\n",
    "    For each user:\n",
    "      1) Gather user's relevant books (rating >=5).\n",
    "      2) Build a 'genre query' from top-5 tags of those relevant books.\n",
    "      3) Get a larger set of recommended items using `recommend_by_multiple_genres`.\n",
    "      4) Skip any book that the user has not rated (rating=0).\n",
    "      5) Keep collecting items (in rank order) up to `top_n`.\n",
    "      6) Compute NDCG (manually) and store it.\n",
    "      7) Print a table showing rank, book_id, user rating, DCG contribution for each user.\n",
    "    Finally, return the average NDCG@k across users.\n",
    "    \"\"\"\n",
    "    user_ids = ratings_subset['user_id'].unique()\n",
    "    ndcg_list = []\n",
    "\n",
    "    # Pre-build a dictionary from goodreads_book_id -> book_id\n",
    "    if 'goodreads_book_id' not in books_tagged.columns:\n",
    "        raise KeyError(\"'goodreads_book_id' column is missing in books_tagged DataFrame.\")\n",
    "    \n",
    "    # Map from goodreads_book_id to book_id\n",
    "    # (If your data is different, adjust accordingly.)\n",
    "    gr2id = {}\n",
    "    for gid in books_tagged['goodreads_book_id']:\n",
    "        gr2id[gid] = gid  # If they are truly the same, or else do a real map\n",
    "\n",
    "    # Alternatively, if books_tagged *does* have a separate 'book_id' column:\n",
    "    #   gr2id = dict(zip(books_tagged['goodreads_book_id'], books_tagged['book_id']))\n",
    "\n",
    "    all_debug_tables = []  # to store or display if you want\n",
    "\n",
    "    for uid in tqdm(user_ids, desc=\"Evaluating NDCG\"):\n",
    "        # -- A) Get user data\n",
    "        user_data = ratings_subset[ratings_subset['user_id'] == uid].copy()\n",
    "        \n",
    "        # relevant_books = rated >= 5\n",
    "        relevant_books = set(user_data[user_data['rating'] >= 5]['book_id'].unique())\n",
    "        if len(relevant_books) == 0:\n",
    "            continue  # no relevant => skip\n",
    "\n",
    "        # -- B) Build a naive 'genre query' from top 5 tags of relevant books\n",
    "        #    You may need to use a suitable merge or direct indexing. \n",
    "        #    Below: if the 'goodreads_book_id' in books_tagged is the same as\n",
    "        #    the user's 'book_id', it’s simpler, but typically you might need\n",
    "        #    a separate map or join if columns differ.  \n",
    "        #    We'll assume the columns line up or you can adapt as needed.\n",
    "\n",
    "        relevant_tags = books_tagged[books_tagged['goodreads_book_id'].isin(relevant_books)]['tag_name']\n",
    "        all_words = \" \".join(relevant_tags.tolist()).split()\n",
    "        word_counts = Counter(all_words)\n",
    "        top_5_tags = [w for w, c in word_counts.most_common(5)]\n",
    "        if not top_5_tags:\n",
    "            continue\n",
    "        \n",
    "        user_genres = \", \".join(top_5_tags)\n",
    "\n",
    "        # -- C) Get a larger set of recommendations\n",
    "        #    We'll ask for top_n * 5 to have enough items to skip from.\n",
    "        recs = recommend_by_multiple_genres(user_genres, top_n=top_n * 5)\n",
    "        # recs should have 'goodreads_book_id' in rank order\n",
    "        recommended_gids = recs['goodreads_book_id'].tolist()\n",
    "\n",
    "        # -- D) Build a final list that ONLY includes items user rated >0\n",
    "        #       i.e. skip rating=0. Keep collecting until we have `top_n`.\n",
    "        final_recs = []\n",
    "        for gid in recommended_gids:\n",
    "            bk_id = gr2id.get(gid, None)\n",
    "            if bk_id is None:\n",
    "                continue  # not in dictionary\n",
    "\n",
    "            # Check user's rating\n",
    "            row = user_data[user_data['book_id'] == bk_id]\n",
    "            user_rating = row['rating'].values[0] if not row.empty else 0\n",
    "            if user_rating > 0:\n",
    "                final_recs.append(bk_id)\n",
    "                if len(final_recs) == top_n:\n",
    "                    break\n",
    "\n",
    "        if len(final_recs) < 1:\n",
    "            # No recommended items that user actually rated => skip\n",
    "            continue\n",
    "\n",
    "        # -- E) Compute NDCG for these final recommendations\n",
    "        ndcg_val, df_debug = compute_ndcg_at_k(\n",
    "            ground_truth_ids=relevant_books,\n",
    "            recommended_ids=final_recs,\n",
    "            user_data=user_data,\n",
    "            k=top_n\n",
    "        )\n",
    "        ndcg_list.append(ndcg_val)\n",
    "\n",
    "        first = True\n",
    "        if first:\n",
    "            all_debug_tables.append(df_debug)\n",
    "            first = False \n",
    "        # Print a debug table for this user\n",
    "        # print(f\"\\nUser: {uid}  (NDCG@{top_n} = {ndcg_val:.4f})\")\n",
    "        # print(df_debug.to_string(index=False))  # or display as you like\n",
    "        # print(\"----------------------------------------------------\")\n",
    "\n",
    "    # -- F) Return the average\n",
    "    if ndcg_list:\n",
    "        return np.mean(ndcg_list)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# Example usage:\n",
    "avg_ndcg = evaluate_ndcg(filtered_ratings, top_n=10)\n",
    "print(f\"\\nGlobal Average NDCG@10 = {avg_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top users with the most rated books: [28158, 7563, 24143, 37834, 6630]\n",
      "No data found for user 6630.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  book_id  rating\n",
      "0        19009       56       2\n",
      "1        10484     5500       3\n",
      "2         3106      456       3\n",
      "3        44407     3647       5\n",
      "4         5419     6753       3\n",
      "...        ...      ...     ...\n",
      "74115     9814     5006       4\n",
      "74116    39590       12       5\n",
      "74117    38866     3070       5\n",
      "74118    50769      345       2\n",
      "74119    22529     2405       3\n",
      "\n",
      "[74120 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_ratings_20p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 1/3996 [00:01<1:21:50,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** DEBUG TABLE FOR USER: 7 **\n",
      "   Rank  book_id  User Rating  Relevance  Predicted Score\n",
      "0     1      416            5          1         3.304666\n",
      "1     2      760            5          1         3.304666\n",
      "2     3      612            5          1         3.304666\n",
      "3     4     3711            5          1         3.304666\n",
      "4     5       55            5          1         3.304666\n",
      "5     6     2487            5          1         3.304666\n",
      "User 7 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 3/3996 [00:01<38:02,  1.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 75 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 4/3996 [00:02<40:39,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 143 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 5/3996 [00:03<42:58,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 145 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 6/3996 [00:04<43:57,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 173 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 7/3996 [00:04<44:37,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 178 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 8/3996 [00:05<45:09,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 202 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 9/3996 [00:06<45:01,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 215 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[183], line 126\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 126\u001b[0m avg_ndcg \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_ndcg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_ratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAverage NDCG@10 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_ndcg\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[183], line 48\u001b[0m, in \u001b[0;36mevaluate_ndcg\u001b[0;34m(ratings_subset, top_n)\u001b[0m\n\u001b[1;32m     46\u001b[0m len_books \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(books_df)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# print(f\"Number of books in the dataset: {len_books}\")\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m recs \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_by_multiple_genres\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_genres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlen_books\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m recommended_gids \u001b[38;5;241m=\u001b[39m recs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoodreads_book_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# D) Build the final list:\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#    - Skip items that the user explicitly rated <5\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#    - Keep items user rated ≥5\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[161], line 13\u001b[0m, in \u001b[0;36mrecommend_by_multiple_genres\u001b[0;34m(user_genres, top_n)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease input at least one genre!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Embed each genre separately\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m genre_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenre_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Compute average embedding (user profile)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m user_embedding \u001b[38;5;241m=\u001b[39m genre_embeddings\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:623\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 623\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    625\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:690\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    689\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:393\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    391\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 393\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# If the AutoModel is wrapped with a PeftModelForFeatureExtraction, then it may have added virtual tokens\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# We need to extend the attention mask to include these virtual tokens, or the pooling will fail\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:943\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    936\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_causal_attention_mask_for_sdpa(\n\u001b[1;32m    937\u001b[0m             attention_mask,\n\u001b[1;32m    938\u001b[0m             input_shape,\n\u001b[1;32m    939\u001b[0m             embedding_output,\n\u001b[1;32m    940\u001b[0m             past_key_values_length,\n\u001b[1;32m    941\u001b[0m         )\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_4d_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_length\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;66;03m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;66;03m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[39;00m\n\u001b[1;32m    949\u001b[0m     extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extended_attention_mask(attention_mask, input_shape)\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:444\u001b[0m, in \u001b[0;36m_prepare_4d_attention_mask_for_sdpa\u001b[0;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[1;32m    441\u001b[0m is_tracing \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mProxy) \u001b[38;5;129;01mor\u001b[39;00m is_torchdynamo_compiling()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# torch.jit.trace, symbolic_trace and torchdynamo with fullgraph=True are unable to capture data-dependent controlflows.\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate_ndcg(ratings_subset, top_n=10):\n",
    "    \"\"\"\n",
    "    Modified so that:\n",
    "     - We DO skip items that the user rated but rated <5.\n",
    "       This effectively ignores items the user explicitly\n",
    "       disliked or gave a low rating to, ensuring we move\n",
    "       further down the recommendation list until we find\n",
    "       either not-rated (0) or relevant (≥5).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import ndcg_score\n",
    "    from collections import Counter\n",
    "    import pandas as pd\n",
    "    \n",
    "    user_ids = ratings_subset['user_id'].unique()\n",
    "    ndcg_list = []\n",
    "\n",
    "    # Pre-build a dictionary from goodreads_book_id -> book_id\n",
    "    if 'goodreads_book_id' not in books_tagged.columns:\n",
    "        raise KeyError(\"'goodreads_book_id' column is missing in books_tagged DataFrame.\")\n",
    "    gr2id = books_tagged.set_index('goodreads_book_id').index.to_series().to_dict()\n",
    "\n",
    "    first_user_debug = True  # We will only show the table for the first user\n",
    "\n",
    "    for uid in tqdm(user_ids, desc=\"Evaluating NDCG (skip low-rated)\"):\n",
    "        # A) Get user data\n",
    "        user_data = ratings_subset[ratings_subset['user_id'] == uid]\n",
    "        # Relevant books = rated ≥ 5\n",
    "        relevant_books = set(user_data[user_data['rating'] >= 5]['book_id'].unique())\n",
    "        if len(relevant_books) == 0:\n",
    "            continue\n",
    "\n",
    "        # B) Build a naive 'genre query' from top 5 tags of relevant books\n",
    "        relevant_tags = books_tagged[books_tagged['goodreads_book_id'].isin(relevant_books)]['tag_name']\n",
    "        from collections import Counter\n",
    "        all_words = \" \".join(relevant_tags.tolist()).split()\n",
    "        word_counts = Counter(all_words)\n",
    "        top_5_tags = [w for w, c in word_counts.most_common(5)]\n",
    "        if not top_5_tags:\n",
    "            continue\n",
    "\n",
    "        user_genres = \", \".join(top_5_tags)\n",
    "\n",
    "        # C) Get a larger recommendation list\n",
    "        len_books = len(books_df)\n",
    "        # print(f\"Number of books in the dataset: {len_books}\")\n",
    "        recs = recommend_by_multiple_genres(user_genres, len_books)\n",
    "        recommended_gids = recs['goodreads_book_id'].tolist()\n",
    "\n",
    "        # D) Build the final list:\n",
    "        #    - Skip items that the user explicitly rated <5\n",
    "        #    - Keep items user rated ≥5\n",
    "        final_recs = []\n",
    "        for gid in recommended_gids:\n",
    "            bk_id = gr2id.get(gid, None)\n",
    "            if bk_id is None:\n",
    "                continue  # not found in dictionary\n",
    "\n",
    "            row = user_data[user_data['book_id'] == bk_id]\n",
    "            if not row.empty:\n",
    "                user_rating = row['rating'].values[0]\n",
    "            else:\n",
    "                continue  # Skip if the user never rated this book\n",
    "\n",
    "            # ### CHANGED HERE ###\n",
    "            # If the user did rate it and rating < 5 => skip it\n",
    "            if user_rating > 0 and user_rating < 5:\n",
    "                continue\n",
    "\n",
    "            # Otherwise (rating=0 or rating>=5), include it\n",
    "            final_recs.append(bk_id)\n",
    "\n",
    "            if len(final_recs) == top_n:\n",
    "                break\n",
    "\n",
    "        recommended_top_k = final_recs\n",
    "        if len(recommended_top_k) < 2:\n",
    "            continue\n",
    "\n",
    "        # Compute a binary relevance label for each item in final_recs\n",
    "        # (1 if user actually rated ≥5, 0 otherwise)\n",
    "        relevance = [1 if b in relevant_books else 0 for b in recommended_top_k]\n",
    "\n",
    "        # We create some dummy predicted scores just to have a strictly decreasing\n",
    "        # list: e.g. [N, N-1, ..., 1].\n",
    "        dcg = 0.0\n",
    "        for i, rel in enumerate(relevance):\n",
    "            dcg += rel / np.log2(i + 2)  # i+2 because log2(1) is undefined\n",
    "        predicted_scores = [dcg] * len(recommended_top_k)\n",
    "\n",
    "        # Show debug table for the first user only\n",
    "        if first_user_debug:\n",
    "            debug_rows = []\n",
    "            for i, book_id in enumerate(recommended_top_k):\n",
    "                # The user rating for this book:\n",
    "                row = user_data.loc[user_data['book_id'] == book_id, 'rating']\n",
    "                user_rating = row.values[0] if not row.empty else user_rating\n",
    "                debug_rows.append({\n",
    "                    'Rank': i + 1,\n",
    "                    'book_id': book_id,\n",
    "                    'User Rating': user_rating,\n",
    "                    'Relevance': 1 if book_id in relevant_books else 0,\n",
    "                    'Predicted Score': predicted_scores[i]\n",
    "                })\n",
    "\n",
    "            df_debug = pd.DataFrame(debug_rows)\n",
    "            print(\"** DEBUG TABLE FOR USER:\", uid, \"**\")\n",
    "            print(df_debug)\n",
    "            \n",
    "            first_user_debug = False  # do not print for subsequent users\n",
    "\n",
    "        # Compute NDCG for this user\n",
    "        y_true = np.array([relevance])\n",
    "        y_score = np.array([predicted_scores])\n",
    "        ndcg_val = ndcg_score(y_true, y_score) \n",
    "        ndcg_list.append(ndcg_val)\n",
    "        \n",
    "        print(f\"User {uid} NDCG@{top_n}: {ndcg_val:.4f}\")\n",
    "\n",
    "    if ndcg_list:\n",
    "        return np.mean(ndcg_list)\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "avg_ndcg = evaluate_ndcg(filtered_ratings, top_n=10)\n",
    "print(f\"\\nAverage NDCG@10 = {avg_ndcg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpy_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
