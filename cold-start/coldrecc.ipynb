{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trunkooze/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load data\n",
    "clean_folder = \"clean\"\n",
    "books_df = pd.read_csv(os.path.join(clean_folder, \"books.csv\"))\n",
    "book_tags_df = pd.read_csv(os.path.join(clean_folder, \"book_tags.csv\"))\n",
    "tags_df = pd.read_csv(os.path.join(clean_folder, \"tags.csv\"))\n",
    "\n",
    "# # Standardize column name for merging\n",
    "# book_tags_df.rename(columns={'book_id': 'book_id'}, inplace=True)\n",
    "\n",
    "# # Rename 'book_id' in books_df to 'book_id' for merging\n",
    "# books_df.rename(columns={'book_id': 'book_id'}, inplace=True)\n",
    "\n",
    "# Merge book_tags with tag names\n",
    "book_tags_merged = pd.merge(book_tags_df, tags_df, on='tag_id', how='inner')\n",
    "\n",
    "# Merge with books\n",
    "books_with_tags = pd.merge(\n",
    "    books_df[['book_id', 'title', 'authors', 'average_rating',\n",
    "              'ratings_count', 'original_publication_year', 'language_code']],\n",
    "    book_tags_merged,\n",
    "    on='book_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Group by book and concatenate tag names into a single string\n",
    "books_tagged = books_with_tags.groupby('book_id').agg({\n",
    "    'title': 'first',\n",
    "    'authors': 'first',\n",
    "    'original_publication_year': 'first',\n",
    "    'language_code': 'first',\n",
    "    'tag_name': lambda x: ' '.join(set(x))  # deduplicated tag list\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = SentenceTransformer('BAAI/bge-m3')\n",
    "\n",
    "# Encode tag text for each book\n",
    "books_tagged['tag_text'] = books_tagged['tag_name']\n",
    "book_tag_embeddings0 = model.encode(books_tagged['tag_text'].tolist(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_by_multiple_genres(user_genres, top_n=10):\n",
    "    \"\"\"\n",
    "    user_genres: str — comma-separated genres, e.g., \"Fantasy, Mystery, Romance\"\n",
    "    top_n: int — number of results to return\n",
    "    \"\"\"\n",
    "    # Parse and clean genres\n",
    "    genre_list = [g.strip() for g in user_genres.split(',') if g.strip()]\n",
    "    \n",
    "    if not genre_list:\n",
    "        raise ValueError(\"Please input at least one genre!\")\n",
    "\n",
    "    # Embed each genre separately\n",
    "    genre_embeddings = model.encode(genre_list, convert_to_tensor=True)\n",
    "\n",
    "    # Compute average embedding (user profile)\n",
    "    user_embedding = genre_embeddings.mean(dim=0)\n",
    "\n",
    "    # Compute cosine similarity with all books\n",
    "    scores = util.pytorch_cos_sim(user_embedding, book_tag_embeddings0)[0]\n",
    "    top_results = scores.topk(top_n)\n",
    "\n",
    "    # Extract matching rows\n",
    "    results = books_tagged.iloc[top_results[1].cpu().numpy()].copy()\n",
    "    results['similarity'] = top_results[0].cpu().numpy()\n",
    "    return results[[\n",
    "        'book_id', 'title', 'authors', 'original_publication_year',\n",
    "        'language_code', 'similarity'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      book_id                                     title  \\\n",
      "6637     6638          Cross My Heart (Alex Cross, #21)   \n",
      "5691     5692         Alex Cross, Run (Alex Cross, #20)   \n",
      "4021     4022           Cross Country (Alex Cross, #14)   \n",
      "8466     8467        Silken Prey (Lucas Davenport, #23)   \n",
      "6293     6294                Private Games (Private #3)   \n",
      "3692     3693        Buried Prey (Lucas Davenport, #21)   \n",
      "4489     4490          Kill Alex Cross (Alex Cross #18)   \n",
      "8643     8644               Private London (Private #4)   \n",
      "7937     7938  I, Michael Bennett (Michael Bennett, #5)   \n",
      "2980     2981            Double Cross (Alex Cross, #13)   \n",
      "\n",
      "                                authors  original_publication_year  \\\n",
      "6637                    James Patterson                     2013.0   \n",
      "5691                    James Patterson                     2013.0   \n",
      "4021                    James Patterson                     2008.0   \n",
      "8466                      John Sandford                     2013.0   \n",
      "6293  James Patterson, Mark T. Sullivan                     2012.0   \n",
      "3692                      John Sandford                     2011.0   \n",
      "4489                    James Patterson                     2011.0   \n",
      "8643      James Patterson, Mark Pearson                     2011.0   \n",
      "7937  James Patterson, Michael Ledwidge                     2012.0   \n",
      "2980                    James Patterson                     2007.0   \n",
      "\n",
      "     language_code  similarity  \n",
      "6637           eng    0.643312  \n",
      "5691          None    0.609955  \n",
      "4021           eng    0.604908  \n",
      "8466           eng    0.602489  \n",
      "6293           eng    0.600157  \n",
      "3692           eng    0.599611  \n",
      "4489           eng    0.595316  \n",
      "8643           eng    0.591713  \n",
      "7937           eng    0.589826  \n",
      "2980           eng    0.588552  \n"
     ]
    }
   ],
   "source": [
    "user_input = \"Fantasy, Paranormal, Fiction, Science Fiction, Graphic Novels, Novel, Urban Fiction\"\n",
    "recommendations = recommend_by_multiple_genres(user_input, top_n=10)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(os.path.join(clean_folder, \"ratings.csv\"))\n",
    "to_read_test_df = pd.read_csv(os.path.join(clean_folder, \"to_read_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible users: 16150\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------\n",
    "# 4. Filter Users + Sample\n",
    "# ------------------------------------\n",
    "#   We'll keep only users who rated >60 and <160 books,\n",
    "#   then randomly sample 20% of those rating rows.\n",
    "\n",
    "# Count how many ratings each user did\n",
    "user_counts = ratings_df.groupby('user_id')['book_id'].count().reset_index()\n",
    "user_counts.rename(columns={'book_id': 'count_ratings'}, inplace=True)\n",
    "\n",
    "# Keep those who rated between 60 and 160\n",
    "eligible_users = user_counts[\n",
    "    (user_counts['count_ratings'] > 30) &\n",
    "    (user_counts['count_ratings'] < 100)\n",
    "]\n",
    "print(f\"Eligible users: {len(eligible_users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to keep only those users' ratings\n",
    "filtered_ratings = pd.merge(\n",
    "    ratings_df,\n",
    "    eligible_users[['user_id']],\n",
    "    on='user_id',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered user count: 16150\n",
      "Filtered ratings shape: (1355729, 3)\n",
      "User IDs in filtered ratings:\n",
      "[    2     6     8 ... 52013 33111 49802]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Filtered user count: {len(eligible_users)}\")\n",
    "print(f\"Filtered ratings shape: {filtered_ratings.shape}\")\n",
    "\n",
    "# print user id in filtered ratings\n",
    "print(\"User IDs in filtered ratings:\")\n",
    "print(filtered_ratings['user_id'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "# ------------------------------------\n",
    "# input test file\n",
    "# loop to all user\n",
    "# get user rated book from ratings.csv\n",
    "# get tag from first 3 book compare to tag_id in UI_tag.csv most match use that genre as a genre to test as user_test_genre\n",
    "# get first 5 book from to_read_test.csv as wishlist (will be goal of evaluation)\n",
    "# get recommendation from recommend_by_multiple_genres(user_test_genre, 5)\n",
    "# compare the recommendation with wishlist score using dcg\n",
    "# sum up all the score\n",
    "# end loop\n",
    "# average the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG: 100%|██████████| 16150/16150 [00:42<00:00, 377.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG Score: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Evaluation BEST ONE\n",
    "# ------------------------------------\n",
    "# input test file\n",
    "# loop to all user\n",
    "# get user rated book from ratings.csv\n",
    "# get tag from first 3 book compare to tag_id in UI_tag.csv most match use that genre as a genre to test as user_test_genre\n",
    "# get first 5 book from to_read_test.csv as wishlist (will be goal of evaluation)\n",
    "# get recommendation from recommend_by_multiple_genres(user_test_genre, 5)\n",
    "# compare the recommendation with wishlist score using ndcg\n",
    "# sum up all the score\n",
    "# end loop\n",
    "# average the score\n",
    "# ------------------------------------\n",
    "\n",
    "def evaluate_ndcg(eligible_users, ratings_df, books_tagged, to_read_test_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Evaluate the NDCG score for recommendations.\n",
    "\n",
    "    Parameters:\n",
    "    - eligible_users: DataFrame containing eligible user IDs.\n",
    "    - ratings_df: DataFrame containing user ratings.\n",
    "    - books_tagged: DataFrame containing books with their tags.\n",
    "    - to_read_test: DataFrame containing users' wishlist books.\n",
    "    - top_n: Number of recommendations to consider for NDCG calculation.\n",
    "\n",
    "    Returns:\n",
    "    - average_ndcg_score: The average NDCG score across all users.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables for evaluation\n",
    "    total_ndcg_score = 0\n",
    "    user_count = 0\n",
    "\n",
    "    # Loop through all eligible users with tqdm progress bar\n",
    "    for user_id in tqdm(eligible_users['user_id'], desc=\"Evaluating NDCG\"):\n",
    "        # Get books rated by the user\n",
    "        user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "        rated_books = user_ratings.sort_values(by='rating', ascending=False).head(3)['book_id'].tolist()\n",
    "\n",
    "        # Get tags for the top 3 rated books\n",
    "        relevant_tags = books_tagged[books_tagged['book_id'].isin(rated_books)]['tag_name']\n",
    "        all_words = \" \".join(relevant_tags.tolist()).split()\n",
    "        word_counts = Counter(all_words)\n",
    "        top_tags = [w for w, c in word_counts.most_common(5)]\n",
    "        if not top_tags:\n",
    "            continue\n",
    "\n",
    "        user_test_genre = \", \".join(top_tags)\n",
    "\n",
    "        # Get the user's wishlist (goal of evaluation)\n",
    "        wishlist = to_read_test_df[to_read_test_df['user_id'] == user_id]['book_id'].tolist()\n",
    "        if not wishlist:\n",
    "            continue\n",
    "\n",
    "        # Get recommendations\n",
    "        recommendations = recommend_by_multiple_genres(user_test_genre, top_n=top_n)\n",
    "        recommended_books = recommendations['book_id'].tolist()\n",
    "\n",
    "        # Calculate DCG score\n",
    "        dcg_score = 0\n",
    "        for i, book_id in enumerate(recommended_books):\n",
    "            if book_id in wishlist:  # check if the recommended book is in the wishlist\n",
    "                dcg_score += 1 / math.log2(i + 2)  # DCG formula\n",
    "\n",
    "        # Calculate IDCG score\n",
    "        idcg_score = 0\n",
    "        for i in range(min(len(wishlist), top_n)):\n",
    "            idcg_score += 1 / math.log2(i + 2)  # Ideal DCG formula\n",
    "\n",
    "        # Calculate NDCG score\n",
    "        ndcg_score = dcg_score / idcg_score if idcg_score > 0 else 0\n",
    "        total_ndcg_score += ndcg_score\n",
    "        user_count += 1\n",
    "\n",
    "    # Calculate average NDCG score\n",
    "    average_ndcg_score = total_ndcg_score / user_count if user_count > 0 else 0\n",
    "    return average_ndcg_score\n",
    "\n",
    "evaluation_score = evaluate_ndcg(eligible_users, ratings_df, books_tagged, to_read_test_df)\n",
    "print(f\"Average NDCG Score: {evaluation_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG: 100%|██████████| 3996/3996 [03:25<00:00, 19.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Average NDCG@10 = 0.4389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "def compute_ndcg_at_k(ground_truth_ids, recommended_ids, user_data, k=10):\n",
    "    \"\"\"\n",
    "    Compute NDCG for a single user at cutoff k, manually.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    ground_truth_ids : set\n",
    "        Set of book_ids the user rated >= 5 (i.e. 'relevant').\n",
    "    recommended_ids : list\n",
    "        List of recommended book_ids in the final top-k (rank order).\n",
    "    user_data : pd.DataFrame\n",
    "        The subset of the ratings DataFrame for this user alone\n",
    "        (so we can look up the actual rating for each book).\n",
    "    k : int\n",
    "        The number of items to consider (already ensured recommended_ids has up to k items).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndcg_val : float\n",
    "        The NDCG for this user at k.\n",
    "    df_debug : pd.DataFrame\n",
    "        A table showing rank, book_id, actual rating, item-level DCG\n",
    "        (so we can see how DCG is accumulated).\n",
    "    \"\"\"\n",
    "    recommended_top_k = recommended_ids[:k]\n",
    "    \n",
    "    # 1) Build a binary relevance list: 1 if rating >=5, else 0\n",
    "    relevance = [1 if b in ground_truth_ids else 0 for b in recommended_top_k]\n",
    "    \n",
    "    # 2) Compute DCG for each rank i in [0..k-1], storing item-level contributions\n",
    "    dcg_values = []\n",
    "    for i, rel in enumerate(relevance):\n",
    "        rank = i + 1  # rank is 1-based\n",
    "        dcg_i = (2 ** rel - 1) / math.log2(rank + 1)\n",
    "        dcg_values.append(dcg_i)\n",
    "    \n",
    "    dcg = sum(dcg_values)\n",
    "    \n",
    "    # 3) Compute IDCG by sorting relevance in descending order\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    idcg_values = []\n",
    "    for i, rel in enumerate(ideal_relevance):\n",
    "        rank = i + 1\n",
    "        idcg_i = (2 ** rel - 1) / math.log2(rank + 1)\n",
    "        idcg_values.append(idcg_i)\n",
    "    \n",
    "    idcg = sum(idcg_values)\n",
    "    ndcg_val = dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    # Build a debug DataFrame\n",
    "    debug_rows = []\n",
    "    for i, book_id in enumerate(recommended_top_k):\n",
    "        rank = i + 1\n",
    "        # Actual rating from user_data\n",
    "        row = user_data[user_data['book_id'] == book_id]\n",
    "        rating = row['rating'].values[0] if not row.empty else 0\n",
    "        \n",
    "        debug_rows.append({\n",
    "            'Rank': rank,\n",
    "            'book_id': book_id,\n",
    "            'User Rating': rating,\n",
    "            'DCG Contribution': dcg_values[i]\n",
    "        })\n",
    "        \n",
    "    df_debug = pd.DataFrame(debug_rows)\n",
    "    \n",
    "    return ndcg_val, df_debug\n",
    "\n",
    "def evaluate_ndcg(ratings_subset, top_n=10):\n",
    "    \"\"\"\n",
    "    For each user:\n",
    "      1) Gather user's relevant books (rating >=5).\n",
    "      2) Build a 'genre query' from top-5 tags of those relevant books.\n",
    "      3) Get a larger set of recommended items using `recommend_by_multiple_genres`.\n",
    "      4) Skip any book that the user has not rated (rating=0).\n",
    "      5) Keep collecting items (in rank order) up to `top_n`.\n",
    "      6) Compute NDCG (manually) and store it.\n",
    "      7) Print a table showing rank, book_id, user rating, DCG contribution for each user.\n",
    "    Finally, return the average NDCG@k across users.\n",
    "    \"\"\"\n",
    "    user_ids = ratings_subset['user_id'].unique()\n",
    "    ndcg_list = []\n",
    "\n",
    "    # Pre-build a dictionary from book_id -> book_id\n",
    "    if 'book_id' not in books_tagged.columns:\n",
    "        raise KeyError(\"'book_id' column is missing in books_tagged DataFrame.\")\n",
    "    \n",
    "    # Map from book_id to book_id\n",
    "    # (If your data is different, adjust accordingly.)\n",
    "    gr2id = {}\n",
    "    for gid in books_tagged['book_id']:\n",
    "        gr2id[gid] = gid  # If they are truly the same, or else do a real map\n",
    "\n",
    "    # Alternatively, if books_tagged *does* have a separate 'book_id' column:\n",
    "    #   gr2id = dict(zip(books_tagged['book_id'], books_tagged['book_id']))\n",
    "\n",
    "    all_debug_tables = []  # to store or display if you want\n",
    "\n",
    "    for uid in tqdm(user_ids, desc=\"Evaluating NDCG\"):\n",
    "        # -- A) Get user data\n",
    "        user_data = ratings_subset[ratings_subset['user_id'] == uid].copy()\n",
    "        \n",
    "        # relevant_books = rated >= 5\n",
    "        relevant_books = set(user_data[user_data['rating'] >= 5]['book_id'].unique())\n",
    "        if len(relevant_books) == 0:\n",
    "            continue  # no relevant => skip\n",
    "\n",
    "        # -- B) Build a naive 'genre query' from top 5 tags of relevant books\n",
    "        #    You may need to use a suitable merge or direct indexing. \n",
    "        #    Below: if the 'book_id' in books_tagged is the same as\n",
    "        #    the user's 'book_id', it’s simpler, but typically you might need\n",
    "        #    a separate map or join if columns differ.  \n",
    "        #    We'll assume the columns line up or you can adapt as needed.\n",
    "\n",
    "        relevant_tags = books_tagged[books_tagged['book_id'].isin(relevant_books)]['tag_name']\n",
    "        all_words = \" \".join(relevant_tags.tolist()).split()\n",
    "        word_counts = Counter(all_words)\n",
    "        top_5_tags = [w for w, c in word_counts.most_common(5)]\n",
    "        if not top_5_tags:\n",
    "            continue\n",
    "        \n",
    "        user_genres = \", \".join(top_5_tags)\n",
    "\n",
    "        # -- C) Get a larger set of recommendations\n",
    "        #    We'll ask for top_n * 5 to have enough items to skip from.\n",
    "        recs = recommend_by_multiple_genres(user_genres, top_n=top_n * 5)\n",
    "        # recs should have 'book_id' in rank order\n",
    "        recommended_gids = recs['goodreads_book_id'].tolist()\n",
    "\n",
    "        # -- D) Build a final list that ONLY includes items user rated >0\n",
    "        #       i.e. skip rating=0. Keep collecting until we have `top_n`.\n",
    "        final_recs = []\n",
    "        for gid in recommended_gids:\n",
    "            bk_id = gr2id.get(gid, None)\n",
    "            if bk_id is None:\n",
    "                continue  # not in dictionary\n",
    "\n",
    "            # Check user's rating\n",
    "            row = user_data[user_data['book_id'] == bk_id]\n",
    "            user_rating = row['rating'].values[0] if not row.empty else 0\n",
    "            if user_rating > 0:\n",
    "                final_recs.append(bk_id)\n",
    "                if len(final_recs) == top_n:\n",
    "                    break\n",
    "\n",
    "        if len(final_recs) < 1:\n",
    "            # No recommended items that user actually rated => skip\n",
    "            continue\n",
    "\n",
    "        # -- E) Compute NDCG for these final recommendations\n",
    "        ndcg_val, df_debug = compute_ndcg_at_k(\n",
    "            ground_truth_ids=relevant_books,\n",
    "            recommended_ids=final_recs,\n",
    "            user_data=user_data,\n",
    "            k=top_n\n",
    "        )\n",
    "        ndcg_list.append(ndcg_val)\n",
    "\n",
    "        first = True\n",
    "        if first:\n",
    "            all_debug_tables.append(df_debug)\n",
    "            first = False\n",
    "        # Print a debug table for this user\n",
    "        print(f\"\\nUser: {uid}  (NDCG@{top_n} = {ndcg_val:.4f})\")\n",
    "        print(df_debug.to_string(index=False))  # or display as you like\n",
    "        print(\"----------------------------------------------------\")\n",
    "\n",
    "    # -- F) Return the average\n",
    "    if ndcg_list:\n",
    "        return np.mean(ndcg_list)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# Example usage:\n",
    "avg_ndcg = evaluate_ndcg(filtered_ratings, top_n=10)\n",
    "print(f\"\\nGlobal Average NDCG@10 = {avg_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top users with the most rated books: [28158, 7563, 24143, 37834, 6630]\n",
      "No data found for user 6630.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  book_id  rating\n",
      "0        19009       56       2\n",
      "1        10484     5500       3\n",
      "2         3106      456       3\n",
      "3        44407     3647       5\n",
      "4         5419     6753       3\n",
      "...        ...      ...     ...\n",
      "74115     9814     5006       4\n",
      "74116    39590       12       5\n",
      "74117    38866     3070       5\n",
      "74118    50769      345       2\n",
      "74119    22529     2405       3\n",
      "\n",
      "[74120 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_ratings_20p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpy_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
