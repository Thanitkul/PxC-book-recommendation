{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load data\n",
    "clean_folder = \"clean\"\n",
    "books_df = pd.read_csv(os.path.join(clean_folder, \"books.csv\"))\n",
    "book_tags_df = pd.read_csv(os.path.join(clean_folder, \"book_tags.csv\"))\n",
    "tags_df = pd.read_csv(os.path.join(clean_folder, \"tags.csv\"))\n",
    "\n",
    "# # Standardize column name for merging\n",
    "# book_tags_df.rename(columns={'book_id': 'book_id'}, inplace=True)\n",
    "\n",
    "# # Rename 'book_id' in books_df to 'book_id' for merging\n",
    "# books_df.rename(columns={'book_id': 'book_id'}, inplace=True)\n",
    "\n",
    "# Merge book_tags with tag names\n",
    "book_tags_merged = pd.merge(book_tags_df, tags_df, on='tag_id', how='inner')\n",
    "\n",
    "# Merge with books\n",
    "books_with_tags = pd.merge(\n",
    "    books_df[['book_id', 'title', 'authors', 'average_rating',\n",
    "              'ratings_count', 'original_publication_year', 'language_code']],\n",
    "    book_tags_merged,\n",
    "    on='book_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Group by book and concatenate tag names into a single string\n",
    "books_tagged = books_with_tags.groupby('book_id').agg({\n",
    "    'title': 'first',\n",
    "    'authors': 'first',\n",
    "    'original_publication_year': 'first',\n",
    "    'language_code': 'first',\n",
    "    'tag_name': lambda x: ' '.join(set(x))  # deduplicated tag list\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = SentenceTransformer('BAAI/bge-m3')\n",
    "\n",
    "# Encode tag text for each book\n",
    "books_tagged['tag_text'] = books_tagged['tag_name']\n",
    "book_tag_embeddings0 = model.encode(books_tagged['tag_text'].tolist(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_by_multiple_genres(user_genres, top_n=10):\n",
    "    \"\"\"\n",
    "    user_genres: str — comma-separated genres, e.g., \"Fantasy, Mystery, Romance\"\n",
    "    top_n: int — number of results to return\n",
    "    \"\"\"\n",
    "    # Parse and clean genres\n",
    "    genre_list = [g.strip() for g in user_genres.split(',') if g.strip()]\n",
    "    \n",
    "    if not genre_list:\n",
    "        raise ValueError(\"Please input at least one genre!\")\n",
    "\n",
    "    # Embed each genre separately\n",
    "    genre_embeddings = model.encode(genre_list, convert_to_tensor=True)\n",
    "\n",
    "    # Compute average embedding (user profile)\n",
    "    user_embedding = genre_embeddings.mean(dim=0)\n",
    "\n",
    "    # Compute cosine similarity with all books\n",
    "    scores = util.pytorch_cos_sim(user_embedding, book_tag_embeddings0)[0]\n",
    "    top_results = scores.topk(top_n)\n",
    "\n",
    "    # Extract matching rows\n",
    "    results = books_tagged.iloc[top_results[1].cpu().numpy()].copy()\n",
    "    results['similarity'] = top_results[0].cpu().numpy()\n",
    "    return results[[\n",
    "        'book_id', 'title', 'authors', 'original_publication_year',\n",
    "        'language_code', 'similarity'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      book_id                                    title  \\\n",
      "6637     6638         Cross My Heart (Alex Cross, #21)   \n",
      "5691     5692        Alex Cross, Run (Alex Cross, #20)   \n",
      "8633     8634                           حوجن [Ḥawjan]   \n",
      "8970     8971   If I Stay Collection (If I Stay, #1-2)   \n",
      "4489     4490         Kill Alex Cross (Alex Cross #18)   \n",
      "8550     8551  The Queen's Poisoner (Kingfountain, #1)   \n",
      "2985     2986             Hidden (House of Night, #10)   \n",
      "4021     4022          Cross Country (Alex Cross, #14)   \n",
      "6293     6294               Private Games (Private #3)   \n",
      "5959     5960  Dragon Haven (Rain Wild Chronicles, #2)   \n",
      "\n",
      "                                           authors  average_rating  \\\n",
      "6637                               James Patterson            4.03   \n",
      "5691                               James Patterson            4.03   \n",
      "8633  Ibraheem Abbas, إبراهيم عباس, Yasser Bahjatt            3.75   \n",
      "8970                                  Gayle Forman            4.24   \n",
      "4489                               James Patterson            4.00   \n",
      "8550                                  Jeff Wheeler            4.07   \n",
      "2985                       P.C. Cast, Kristin Cast            3.98   \n",
      "4021                               James Patterson            3.83   \n",
      "6293             James Patterson, Mark T. Sullivan            3.83   \n",
      "5959                                    Robin Hobb            4.06   \n",
      "\n",
      "      ratings_count  original_publication_year language_code  similarity  \n",
      "6637          10946                     2013.0           eng    0.592851  \n",
      "5691          14434                     2013.0          None    0.590717  \n",
      "8633          10203                     2013.0           ara    0.583359  \n",
      "8970           7823                     2014.0           eng    0.579380  \n",
      "4489          20206                     2011.0           eng    0.577814  \n",
      "8550          14126                     2016.0         en-GB    0.574422  \n",
      "2985          38594                     2012.0         en-US    0.574278  \n",
      "4021          26068                     2008.0           eng    0.570447  \n",
      "6293          14358                     2012.0           eng    0.569781  \n",
      "5959          15807                     2010.0         en-US    0.569519  \n"
     ]
    }
   ],
   "source": [
    "user_input = \"Fantasy, Paranormal, Fiction, Science Fiction, Graphic Novels, Novel, Urban Fiction\"\n",
    "recommendations = recommend_by_multiple_genres(user_input, top_n=10)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(os.path.join(clean_folder, \"ratings.csv\"))\n",
    "to_read_test_df = pd.read_csv(os.path.join(clean_folder, \"to_read_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible users: 16150\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------\n",
    "# 4. Filter Users + Sample\n",
    "# ------------------------------------\n",
    "#   We'll keep only users who rated >60 and <160 books,\n",
    "#   then randomly sample 20% of those rating rows.\n",
    "\n",
    "# Count how many ratings each user did\n",
    "user_counts = ratings_df.groupby('user_id')['book_id'].count().reset_index()\n",
    "user_counts.rename(columns={'book_id': 'count_ratings'}, inplace=True)\n",
    "\n",
    "# Keep those who rated between 60 and 160\n",
    "eligible_users = user_counts[\n",
    "    (user_counts['count_ratings'] > 30) &\n",
    "    (user_counts['count_ratings'] < 100)\n",
    "]\n",
    "print(f\"Eligible users: {len(eligible_users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to keep only those users' ratings\n",
    "filtered_ratings = pd.merge(\n",
    "    ratings_df,\n",
    "    eligible_users[['user_id']],\n",
    "    on='user_id',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered user count: 16150\n",
      "Filtered ratings shape: (1355729, 3)\n",
      "User IDs in filtered ratings:\n",
      "[    2     6     8 ... 52013 33111 49802]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Filtered user count: {len(eligible_users)}\")\n",
    "print(f\"Filtered ratings shape: {filtered_ratings.shape}\")\n",
    "\n",
    "# print user id in filtered ratings\n",
    "print(\"User IDs in filtered ratings:\")\n",
    "print(filtered_ratings['user_id'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "# ------------------------------------\n",
    "# input test file\n",
    "# loop to all user\n",
    "# get user rated book from ratings.csv\n",
    "# get tag from first 3 book compare to tag_id in UI_tag.csv most match use that genre as a genre to test as user_test_genre\n",
    "# get first 5 book from to_read_test.csv as wishlist (will be goal of evaluation)\n",
    "# get recommendation from recommend_by_multiple_genres(user_test_genre, 5)\n",
    "# compare the recommendation with wishlist score using dcg\n",
    "# sum up all the score\n",
    "# end loop\n",
    "# average the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  11%|█         | 1774/16150 [00:09<01:35, 149.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 2129 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  12%|█▏        | 2015/16150 [00:10<01:05, 214.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 3336 is in the wishlist!\n",
      "Recommended Book ID 3687 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  13%|█▎        | 2087/16150 [00:11<01:06, 212.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 4490 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  16%|█▌        | 2529/16150 [00:13<01:15, 181.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 6294 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  17%|█▋        | 2673/16150 [00:14<01:05, 205.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 1098 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  18%|█▊        | 2833/16150 [00:15<01:14, 178.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 286 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  19%|█▊        | 3028/16150 [00:16<01:24, 155.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 3589 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  19%|█▉        | 3080/16150 [00:17<01:22, 157.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 3336 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  23%|██▎       | 3746/16150 [00:20<01:20, 154.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 3878 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  24%|██▍       | 3889/16150 [00:21<01:06, 184.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 5970 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  24%|██▍       | 3908/16150 [00:21<01:09, 177.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 389 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  27%|██▋       | 4360/16150 [00:24<01:14, 157.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 8381 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  28%|██▊       | 4572/16150 [00:26<01:36, 119.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 389 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  30%|███       | 4859/16150 [00:27<01:04, 175.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 7728 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  30%|███       | 4900/16150 [00:28<01:13, 154.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 2875 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  31%|███       | 5025/16150 [00:28<01:05, 169.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 9596 is in the wishlist!\n",
      "Recommended Book ID 286 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  32%|███▏      | 5235/16150 [00:29<00:59, 183.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 225 is in the wishlist!\n",
      "Recommended Book ID 130 is in the wishlist!\n",
      "Recommended Book ID 3064 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  38%|███▊      | 6098/16150 [00:35<01:14, 134.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 3064 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  41%|████      | 6573/16150 [00:37<01:00, 158.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 286 is in the wishlist!\n",
      "Recommended Book ID 286 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  42%|████▏     | 6789/16150 [00:39<00:59, 157.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 286 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  44%|████▎     | 7029/16150 [00:40<00:59, 152.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 2684 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  44%|████▍     | 7096/16150 [00:41<00:55, 162.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 6294 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  46%|████▌     | 7451/16150 [00:43<00:59, 145.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 389 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  52%|█████▏    | 8469/16150 [00:52<00:47, 160.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 3064 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  53%|█████▎    | 8502/16150 [00:52<01:12, 105.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 1098 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  55%|█████▌    | 8922/16150 [00:56<00:54, 133.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 5178 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  56%|█████▋    | 9112/16150 [00:58<01:31, 76.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 8971 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  57%|█████▋    | 9283/16150 [00:59<01:02, 109.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 8797 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  61%|██████    | 9865/16150 [01:04<01:11, 88.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 2986 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  62%|██████▏   | 9968/16150 [01:05<00:35, 172.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 8911 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  63%|██████▎   | 10245/16150 [01:08<01:01, 96.68it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 1919 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  65%|██████▌   | 10502/16150 [01:10<01:07, 84.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 6450 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  66%|██████▌   | 10692/16150 [01:12<00:50, 108.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 5352 is in the wishlist!\n",
      "Recommended Book ID 3044 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  72%|███████▏  | 11571/16150 [01:20<00:46, 97.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 389 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  74%|███████▍  | 11974/16150 [01:23<00:34, 121.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 3589 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  76%|███████▌  | 12298/16150 [01:26<00:42, 89.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 1080 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  78%|███████▊  | 12631/16150 [01:29<00:29, 118.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 389 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  79%|███████▊  | 12699/16150 [01:30<00:30, 113.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 389 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  82%|████████▏ | 13224/16150 [01:35<00:37, 78.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 9876 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  88%|████████▊ | 14145/16150 [01:43<00:19, 104.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 92 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  88%|████████▊ | 14212/16150 [01:43<00:18, 104.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 389 is in the wishlist!\n",
      "Recommended Book ID 286 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  91%|█████████ | 14716/16150 [01:49<00:12, 117.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 8971 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  94%|█████████▍| 15211/16150 [01:53<00:06, 150.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 286 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  94%|█████████▍| 15251/16150 [01:53<00:06, 138.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 286 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  95%|█████████▌| 15398/16150 [01:55<00:07, 99.77it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 5960 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  97%|█████████▋| 15735/16150 [01:58<00:04, 92.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 8268 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  99%|█████████▊| 15938/16150 [02:00<00:01, 115.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 7580 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG:  99%|█████████▉| 15960/16150 [02:01<00:02, 85.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Book ID 1590 is in the wishlist!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating DCG: 100%|██████████| 16150/16150 [02:02<00:00, 131.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average DCG Score: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Evaluation\n",
    "# ------------------------------------\n",
    "# input test file\n",
    "# loop to all user\n",
    "# get user rated book from ratings.csv\n",
    "# get tag from first 3 book compare to tag_id in UI_tag.csv most match use that genre as a genre to test as user_test_genre\n",
    "# get first 5 book from to_read_test.csv as wishlist (will be goal of evaluation)\n",
    "# get recommendation from recommend_by_multiple_genres(user_test_genre, 5)\n",
    "# compare the recommendation with wishlist score using dcg\n",
    "# sum up all the score\n",
    "# end loop\n",
    "# average the score\n",
    "# ------------------------------------\n",
    "\n",
    "def evaluate_dcg(eligible_users, ratings_df, books_tagged, to_read_test, top_n=5):\n",
    "    \"\"\"\n",
    "    Evaluate the DCG score for recommendations.\n",
    "\n",
    "    Parameters:\n",
    "    - eligible_users: DataFrame containing eligible user IDs.\n",
    "    - ratings_df: DataFrame containing user ratings.\n",
    "    - books_tagged: DataFrame containing books with their tags.\n",
    "    - to_read_test: DataFrame containing users' wishlist books.\n",
    "    - top_n: Number of recommendations to consider for DCG calculation.\n",
    "\n",
    "    Returns:\n",
    "    - average_dcg_score: The average DCG score across all users.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize variables for evaluation\n",
    "    total_dcg_score = 0\n",
    "    user_count = 0\n",
    "\n",
    "    # Loop through all eligible users with tqdm progress bar\n",
    "    for user_id in tqdm(eligible_users['user_id'], desc=\"Evaluating DCG\"):\n",
    "        # Get books rated by the user\n",
    "        user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "        rated_books = user_ratings.sort_values(by='rating', ascending=False).head(3)['book_id'].tolist()\n",
    "\n",
    "        # Get tags for the top 3 rated books\n",
    "        relevant_tags = books_tagged[books_tagged['book_id'].isin(rated_books)]['tag_name']\n",
    "        all_words = \" \".join(relevant_tags.tolist()).split()\n",
    "        word_counts = Counter(all_words)\n",
    "        top_tags = [w for w, c in word_counts.most_common(5)]\n",
    "        if not top_tags:\n",
    "            continue\n",
    "\n",
    "        user_test_genre = \", \".join(top_tags)\n",
    "\n",
    "        # Get the user's wishlist (goal of evaluation)\n",
    "        wishlist = to_read_test_df[to_read_test_df['user_id'] == user_id]['book_id'].tolist()\n",
    "        if not wishlist:\n",
    "            continue\n",
    "\n",
    "        # Get recommendations\n",
    "        recommendations = recommend_by_multiple_genres(user_test_genre, top_n=top_n)\n",
    "        recommended_books = recommendations['book_id'].tolist()\n",
    "        \n",
    "        # Print table for recommended books and wishlist\n",
    "        # print(f\"User ID: {user_id}\")\n",
    "        # print(\"Recommended Books:\")\n",
    "        # print(pd.DataFrame(recommendations[['book_id', 'title', 'authors']]))\n",
    "        # print(\"\\nWishlist:\")\n",
    "        # print(pd.DataFrame(to_read_test[to_read_test['user_id'] == user_id][['book_id']]))\n",
    "        # print(\"-\" * 50)\n",
    "        \n",
    "        # Calculate DCG score\n",
    "        dcg_score = 0\n",
    "        for i, book_id in enumerate(recommended_books):\n",
    "            if book_id in wishlist:  # check if the recommended book is in the wishlist\n",
    "                print(f\"Recommended Book ID {book_id} is in the wishlist!\")\n",
    "                dcg_score += 1 / math.log2(i + 2)  # DCG formula\n",
    "\n",
    "        total_dcg_score += dcg_score\n",
    "        user_count += 1\n",
    "\n",
    "    # Calculate average DCG score\n",
    "    average_dcg_score = total_dcg_score / user_count if user_count > 0 else 0\n",
    "    return average_dcg_score\n",
    "\n",
    "evaluation_score = evaluate_dcg(eligible_users, ratings_df, books_tagged, to_read_test_df)\n",
    "print(f\"Average DCG Score: {evaluation_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG: 100%|██████████| 3996/3996 [03:25<00:00, 19.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Average NDCG@10 = 0.4389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "def compute_ndcg_at_k(ground_truth_ids, recommended_ids, user_data, k=10):\n",
    "    \"\"\"\n",
    "    Compute NDCG for a single user at cutoff k, manually.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    ground_truth_ids : set\n",
    "        Set of book_ids the user rated >= 5 (i.e. 'relevant').\n",
    "    recommended_ids : list\n",
    "        List of recommended book_ids in the final top-k (rank order).\n",
    "    user_data : pd.DataFrame\n",
    "        The subset of the ratings DataFrame for this user alone\n",
    "        (so we can look up the actual rating for each book).\n",
    "    k : int\n",
    "        The number of items to consider (already ensured recommended_ids has up to k items).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndcg_val : float\n",
    "        The NDCG for this user at k.\n",
    "    df_debug : pd.DataFrame\n",
    "        A table showing rank, book_id, actual rating, item-level DCG\n",
    "        (so we can see how DCG is accumulated).\n",
    "    \"\"\"\n",
    "    recommended_top_k = recommended_ids[:k]\n",
    "    \n",
    "    # 1) Build a binary relevance list: 1 if rating >=5, else 0\n",
    "    relevance = [1 if b in ground_truth_ids else 0 for b in recommended_top_k]\n",
    "    \n",
    "    # 2) Compute DCG for each rank i in [0..k-1], storing item-level contributions\n",
    "    dcg_values = []\n",
    "    for i, rel in enumerate(relevance):\n",
    "        rank = i + 1  # rank is 1-based\n",
    "        dcg_i = (2 ** rel - 1) / math.log2(rank + 1)\n",
    "        dcg_values.append(dcg_i)\n",
    "    \n",
    "    dcg = sum(dcg_values)\n",
    "    \n",
    "    # 3) Compute IDCG by sorting relevance in descending order\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    idcg_values = []\n",
    "    for i, rel in enumerate(ideal_relevance):\n",
    "        rank = i + 1\n",
    "        idcg_i = (2 ** rel - 1) / math.log2(rank + 1)\n",
    "        idcg_values.append(idcg_i)\n",
    "    \n",
    "    idcg = sum(idcg_values)\n",
    "    ndcg_val = dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    # Build a debug DataFrame\n",
    "    debug_rows = []\n",
    "    for i, book_id in enumerate(recommended_top_k):\n",
    "        rank = i + 1\n",
    "        # Actual rating from user_data\n",
    "        row = user_data[user_data['book_id'] == book_id]\n",
    "        rating = row['rating'].values[0] if not row.empty else 0\n",
    "        \n",
    "        debug_rows.append({\n",
    "            'Rank': rank,\n",
    "            'book_id': book_id,\n",
    "            'User Rating': rating,\n",
    "            'DCG Contribution': dcg_values[i]\n",
    "        })\n",
    "        \n",
    "    df_debug = pd.DataFrame(debug_rows)\n",
    "    \n",
    "    return ndcg_val, df_debug\n",
    "\n",
    "def evaluate_ndcg(ratings_subset, top_n=10):\n",
    "    \"\"\"\n",
    "    For each user:\n",
    "      1) Gather user's relevant books (rating >=5).\n",
    "      2) Build a 'genre query' from top-5 tags of those relevant books.\n",
    "      3) Get a larger set of recommended items using `recommend_by_multiple_genres`.\n",
    "      4) Skip any book that the user has not rated (rating=0).\n",
    "      5) Keep collecting items (in rank order) up to `top_n`.\n",
    "      6) Compute NDCG (manually) and store it.\n",
    "      7) Print a table showing rank, book_id, user rating, DCG contribution for each user.\n",
    "    Finally, return the average NDCG@k across users.\n",
    "    \"\"\"\n",
    "    user_ids = ratings_subset['user_id'].unique()\n",
    "    ndcg_list = []\n",
    "\n",
    "    # Pre-build a dictionary from book_id -> book_id\n",
    "    if 'book_id' not in books_tagged.columns:\n",
    "        raise KeyError(\"'book_id' column is missing in books_tagged DataFrame.\")\n",
    "    \n",
    "    # Map from book_id to book_id\n",
    "    # (If your data is different, adjust accordingly.)\n",
    "    gr2id = {}\n",
    "    for gid in books_tagged['book_id']:\n",
    "        gr2id[gid] = gid  # If they are truly the same, or else do a real map\n",
    "\n",
    "    # Alternatively, if books_tagged *does* have a separate 'book_id' column:\n",
    "    #   gr2id = dict(zip(books_tagged['book_id'], books_tagged['book_id']))\n",
    "\n",
    "    all_debug_tables = []  # to store or display if you want\n",
    "\n",
    "    for uid in tqdm(user_ids, desc=\"Evaluating NDCG\"):\n",
    "        # -- A) Get user data\n",
    "        user_data = ratings_subset[ratings_subset['user_id'] == uid].copy()\n",
    "        \n",
    "        # relevant_books = rated >= 5\n",
    "        relevant_books = set(user_data[user_data['rating'] >= 5]['book_id'].unique())\n",
    "        if len(relevant_books) == 0:\n",
    "            continue  # no relevant => skip\n",
    "\n",
    "        # -- B) Build a naive 'genre query' from top 5 tags of relevant books\n",
    "        #    You may need to use a suitable merge or direct indexing. \n",
    "        #    Below: if the 'book_id' in books_tagged is the same as\n",
    "        #    the user's 'book_id', it’s simpler, but typically you might need\n",
    "        #    a separate map or join if columns differ.  \n",
    "        #    We'll assume the columns line up or you can adapt as needed.\n",
    "\n",
    "        relevant_tags = books_tagged[books_tagged['book_id'].isin(relevant_books)]['tag_name']\n",
    "        all_words = \" \".join(relevant_tags.tolist()).split()\n",
    "        word_counts = Counter(all_words)\n",
    "        top_5_tags = [w for w, c in word_counts.most_common(5)]\n",
    "        if not top_5_tags:\n",
    "            continue\n",
    "        \n",
    "        user_genres = \", \".join(top_5_tags)\n",
    "\n",
    "        # -- C) Get a larger set of recommendations\n",
    "        #    We'll ask for top_n * 5 to have enough items to skip from.\n",
    "        recs = recommend_by_multiple_genres(user_genres, top_n=top_n * 5)\n",
    "        # recs should have 'book_id' in rank order\n",
    "        recommended_gids = recs['goodreads_book_id'].tolist()\n",
    "\n",
    "        # -- D) Build a final list that ONLY includes items user rated >0\n",
    "        #       i.e. skip rating=0. Keep collecting until we have `top_n`.\n",
    "        final_recs = []\n",
    "        for gid in recommended_gids:\n",
    "            bk_id = gr2id.get(gid, None)\n",
    "            if bk_id is None:\n",
    "                continue  # not in dictionary\n",
    "\n",
    "            # Check user's rating\n",
    "            row = user_data[user_data['book_id'] == bk_id]\n",
    "            user_rating = row['rating'].values[0] if not row.empty else 0\n",
    "            if user_rating > 0:\n",
    "                final_recs.append(bk_id)\n",
    "                if len(final_recs) == top_n:\n",
    "                    break\n",
    "\n",
    "        if len(final_recs) < 1:\n",
    "            # No recommended items that user actually rated => skip\n",
    "            continue\n",
    "\n",
    "        # -- E) Compute NDCG for these final recommendations\n",
    "        ndcg_val, df_debug = compute_ndcg_at_k(\n",
    "            ground_truth_ids=relevant_books,\n",
    "            recommended_ids=final_recs,\n",
    "            user_data=user_data,\n",
    "            k=top_n\n",
    "        )\n",
    "        ndcg_list.append(ndcg_val)\n",
    "\n",
    "        first = True\n",
    "        if first:\n",
    "            all_debug_tables.append(df_debug)\n",
    "            first = False\n",
    "        # Print a debug table for this user\n",
    "        print(f\"\\nUser: {uid}  (NDCG@{top_n} = {ndcg_val:.4f})\")\n",
    "        print(df_debug.to_string(index=False))  # or display as you like\n",
    "        print(\"----------------------------------------------------\")\n",
    "\n",
    "    # -- F) Return the average\n",
    "    if ndcg_list:\n",
    "        return np.mean(ndcg_list)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# Example usage:\n",
    "avg_ndcg = evaluate_ndcg(filtered_ratings, top_n=10)\n",
    "print(f\"\\nGlobal Average NDCG@10 = {avg_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top users with the most rated books: [28158, 7563, 24143, 37834, 6630]\n",
      "No data found for user 6630.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  book_id  rating\n",
      "0        19009       56       2\n",
      "1        10484     5500       3\n",
      "2         3106      456       3\n",
      "3        44407     3647       5\n",
      "4         5419     6753       3\n",
      "...        ...      ...     ...\n",
      "74115     9814     5006       4\n",
      "74116    39590       12       5\n",
      "74117    38866     3070       5\n",
      "74118    50769      345       2\n",
      "74119    22529     2405       3\n",
      "\n",
      "[74120 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_ratings_20p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 1/3996 [00:01<1:21:50,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** DEBUG TABLE FOR USER: 7 **\n",
      "   Rank  book_id  User Rating  Relevance  Predicted Score\n",
      "0     1      416            5          1         3.304666\n",
      "1     2      760            5          1         3.304666\n",
      "2     3      612            5          1         3.304666\n",
      "3     4     3711            5          1         3.304666\n",
      "4     5       55            5          1         3.304666\n",
      "5     6     2487            5          1         3.304666\n",
      "User 7 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 3/3996 [00:01<38:02,  1.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 75 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 4/3996 [00:02<40:39,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 143 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 5/3996 [00:03<42:58,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 145 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 6/3996 [00:04<43:57,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 173 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 7/3996 [00:04<44:37,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 178 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 8/3996 [00:05<45:09,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 202 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NDCG (skip low-rated):   0%|          | 9/3996 [00:06<45:01,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 215 NDCG@10: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[183], line 126\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 126\u001b[0m avg_ndcg \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_ndcg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_ratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAverage NDCG@10 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_ndcg\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[183], line 48\u001b[0m, in \u001b[0;36mevaluate_ndcg\u001b[0;34m(ratings_subset, top_n)\u001b[0m\n\u001b[1;32m     46\u001b[0m len_books \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(books_df)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# print(f\"Number of books in the dataset: {len_books}\")\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m recs \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_by_multiple_genres\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_genres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlen_books\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m recommended_gids \u001b[38;5;241m=\u001b[39m recs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoodreads_book_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# D) Build the final list:\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#    - Skip items that the user explicitly rated <5\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#    - Keep items user rated ≥5\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[161], line 13\u001b[0m, in \u001b[0;36mrecommend_by_multiple_genres\u001b[0;34m(user_genres, top_n)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease input at least one genre!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Embed each genre separately\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m genre_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenre_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Compute average embedding (user profile)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m user_embedding \u001b[38;5;241m=\u001b[39m genre_embeddings\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:623\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 623\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    625\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:690\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    689\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:393\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    391\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 393\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# If the AutoModel is wrapped with a PeftModelForFeatureExtraction, then it may have added virtual tokens\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# We need to extend the attention mask to include these virtual tokens, or the pooling will fail\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:943\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    936\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_causal_attention_mask_for_sdpa(\n\u001b[1;32m    937\u001b[0m             attention_mask,\n\u001b[1;32m    938\u001b[0m             input_shape,\n\u001b[1;32m    939\u001b[0m             embedding_output,\n\u001b[1;32m    940\u001b[0m             past_key_values_length,\n\u001b[1;32m    941\u001b[0m         )\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m         extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_4d_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_length\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;66;03m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;66;03m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[39;00m\n\u001b[1;32m    949\u001b[0m     extended_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extended_attention_mask(attention_mask, input_shape)\n",
      "File \u001b[0;32m~/miniconda3/envs/numpy_lab/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:444\u001b[0m, in \u001b[0;36m_prepare_4d_attention_mask_for_sdpa\u001b[0;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[1;32m    441\u001b[0m is_tracing \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mProxy) \u001b[38;5;129;01mor\u001b[39;00m is_torchdynamo_compiling()\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# torch.jit.trace, symbolic_trace and torchdynamo with fullgraph=True are unable to capture data-dependent controlflows.\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate_ndcg(ratings_subset, top_n=10):\n",
    "    \"\"\"\n",
    "    Modified so that:\n",
    "     - We DO skip items that the user rated but rated <5.\n",
    "       This effectively ignores items the user explicitly\n",
    "       disliked or gave a low rating to, ensuring we move\n",
    "       further down the recommendation list until we find\n",
    "       either not-rated (0) or relevant (≥5).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import ndcg_score\n",
    "    from collections import Counter\n",
    "    import pandas as pd\n",
    "    \n",
    "    user_ids = ratings_subset['user_id'].unique()\n",
    "    ndcg_list = []\n",
    "\n",
    "    # Pre-build a dictionary from book_id -> book_id\n",
    "    if 'book_id' not in books_tagged.columns:\n",
    "        raise KeyError(\"'book_id' column is missing in books_tagged DataFrame.\")\n",
    "    gr2id = books_tagged.set_index('book_id').index.to_series().to_dict()\n",
    "\n",
    "    first_user_debug = True  # We will only show the table for the first user\n",
    "\n",
    "    for uid in tqdm(user_ids, desc=\"Evaluating NDCG (skip low-rated)\"):\n",
    "        # A) Get user data\n",
    "        user_data = ratings_subset[ratings_subset['user_id'] == uid]\n",
    "        # Relevant books = rated ≥ 5\n",
    "        relevant_books = set(user_data[user_data['rating'] >= 5]['book_id'].unique())\n",
    "        if len(relevant_books) == 0:\n",
    "            continue\n",
    "\n",
    "        # B) Build a naive 'genre query' from top 5 tags of relevant books\n",
    "        relevant_tags = books_tagged[books_tagged['book_id'].isin(relevant_books)]['tag_name']\n",
    "        from collections import Counter\n",
    "        all_words = \" \".join(relevant_tags.tolist()).split()\n",
    "        word_counts = Counter(all_words)\n",
    "        top_5_tags = [w for w, c in word_counts.most_common(5)]\n",
    "        if not top_5_tags:\n",
    "            continue\n",
    "\n",
    "        user_genres = \", \".join(top_5_tags)\n",
    "\n",
    "        # C) Get a larger recommendation list\n",
    "        len_books = len(books_df)\n",
    "        # print(f\"Number of books in the dataset: {len_books}\")\n",
    "        recs = recommend_by_multiple_genres(user_genres, len_books)\n",
    "        recommended_gids = recs['book_id'].tolist()\n",
    "\n",
    "        # D) Build the final list:\n",
    "        #    - Skip items that the user explicitly rated <5\n",
    "        #    - Keep items user rated ≥5\n",
    "        final_recs = []\n",
    "        for gid in recommended_gids:\n",
    "            bk_id = gr2id.get(gid, None)\n",
    "            if bk_id is None:\n",
    "                continue  # not found in dictionary\n",
    "\n",
    "            row = user_data[user_data['book_id'] == bk_id]\n",
    "            if not row.empty:\n",
    "                user_rating = row['rating'].values[0]\n",
    "            else:\n",
    "                continue  # Skip if the user never rated this book\n",
    "\n",
    "            # ### CHANGED HERE ###\n",
    "            # If the user did rate it and rating < 5 => skip it\n",
    "            if user_rating > 0 and user_rating < 5:\n",
    "                continue\n",
    "\n",
    "            # Otherwise (rating=0 or rating>=5), include it\n",
    "            final_recs.append(bk_id)\n",
    "\n",
    "            if len(final_recs) == top_n:\n",
    "                break\n",
    "\n",
    "        recommended_top_k = final_recs\n",
    "        if len(recommended_top_k) < 2:\n",
    "            continue\n",
    "\n",
    "        # Compute a binary relevance label for each item in final_recs\n",
    "        # (1 if user actually rated ≥5, 0 otherwise)\n",
    "        relevance = [1 if b in relevant_books else 0 for b in recommended_top_k]\n",
    "\n",
    "        # We create some dummy predicted scores just to have a strictly decreasing\n",
    "        # list: e.g. [N, N-1, ..., 1].\n",
    "        dcg = 0.0\n",
    "        for i, rel in enumerate(relevance):\n",
    "            dcg += rel / np.log2(i + 2)  # i+2 because log2(1) is undefined\n",
    "        predicted_scores = [dcg] * len(recommended_top_k)\n",
    "\n",
    "        # Show debug table for the first user only\n",
    "        if first_user_debug:\n",
    "            debug_rows = []\n",
    "            for i, book_id in enumerate(recommended_top_k):\n",
    "                # The user rating for this book:\n",
    "                row = user_data.loc[user_data['book_id'] == book_id, 'rating']\n",
    "                user_rating = row.values[0] if not row.empty else user_rating\n",
    "                debug_rows.append({\n",
    "                    'Rank': i + 1,\n",
    "                    'book_id': book_id,\n",
    "                    'User Rating': user_rating,\n",
    "                    'Relevance': 1 if book_id in relevant_books else 0,\n",
    "                    'Predicted Score': predicted_scores[i]\n",
    "                })\n",
    "\n",
    "            df_debug = pd.DataFrame(debug_rows)\n",
    "            print(\"** DEBUG TABLE FOR USER:\", uid, \"**\")\n",
    "            print(df_debug)\n",
    "            \n",
    "            first_user_debug = False  # do not print for subsequent users\n",
    "\n",
    "        # Compute NDCG for this user\n",
    "        y_true = np.array([relevance])\n",
    "        y_score = np.array([predicted_scores])\n",
    "        ndcg_val = ndcg_score(y_true, y_score) \n",
    "        ndcg_list.append(ndcg_val)\n",
    "        \n",
    "        print(f\"User {uid} NDCG@{top_n}: {ndcg_val:.4f}\")\n",
    "\n",
    "    if ndcg_list:\n",
    "        return np.mean(ndcg_list)\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "avg_ndcg = evaluate_ndcg(filtered_ratings, top_n=10)\n",
    "print(f\"\\nAverage NDCG@10 = {avg_ndcg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpy_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
